---
title: "Assessed Assignment 1"
output:
  html_notebook: default
---

# 1

```{r}
# Stack age and weight vectors into a data frame (matrix) baby_girl
weight <- c(2.99, 3.04, 3.23, 3.60, 3.98, 4.50, 4.60, 4.95, 5.05, 5.35, 5.62, 5.95, 6.09, 6.28, 6.69)
age <- c(1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 20, 22)
baby_girl = data.frame(age, weight)
```

```{r}
# (a) Plot data and fit a simple linear regression model
plot(baby_girl$age, baby_girl$weight,
     xlab = "Age in weeks", ylab = "Weight in kilograms", 
     main = "Weight (kg) against Age (weeks) of a Baby Girl")
baby.lm = lm(weight ~ age, data = baby_girl)
abline(simple_linear_regr_model$coefficient)
summary(simple_linear_regr_model)
```

```{r}
# (b)
summary(baby.lm)
plot(baby.lm)
# If we first take a look at the summary of the model we can see small p-values for both the intercept and the age variable, indicating that both terms are relevant and should be included in the model.
# In addition, the adjusted R^2 is close to 1 indicatng that 98.57 % of the total variance in the data can be explained from the fitted model. And add to that a high f-statistic score of 963 indicating that the model as a whole is a good fit.

# However, when looking at the residual plots we can see a worrying pattern. The residuals should ideally be scattered around on both sides of 0 and have a constant variance. From the residual plot, we can see that the residulas start off ok, but then follow an upward pattern where the residuals take on positive values before plunging back to high negative values in the very end.

# We can see a similar pattern in the normal qq plot where we can see that the distribution of the residuals departs to a certains degree from lineartiy indicating the residuals do not follow a symmetric shape of the normal distribution.
```
 

```{r}
# (c)
baby_girl$age_square <- age * age
baby.lm2 <- lm(weight ~ age + age_square, data = baby_girl)
summary(baby.lm2)
plot(baby.lm2)
# From the summary statistics we can see that the R^2 is even higher when including the age squared variable, although the p-value for the individual age sqaured variable is not as small (> 0.01) the intercept and the orignal age variable (both close to 0). We can also not that the F-statistic has decreased from 963 to 802 when adding the extra quadratic term. 

# The residual plot does look a little bit better after including the quadratic term as the residuals are more randomly scattered and with a fairly constant variance. The normal qq plot also indicate a slighly more normal distribution of the residuals. 
```


```{r}
# (d)
baby_girl$age_cubic <- age * age * age
baby.lm3 <- lm(weight ~ age + age_square + age_cubic, data = baby_girl)
summary(baby.lm3)
plot(baby.lm3)

# Although the adjusted R^2 has gone up to 0.9944, the significance of each individual term has decreased where the quadratic term now has a p-value > 0.05 indicating that we cannot reject the null-hypothesis for this variable. The cubic term is also not as significant with a p-value of 0.0192 which may not be low enough to reject the null hypothesis for the cubic term either. The overall p-value is very small and the F-statistic stay fairly high.

# For the residuals, they look a bit more evenly scattered now with a fairly constant variance. The normal qq plot has also changed, pushing the residuals closer the line, indicating a more normal distribution of the residuals.
```

```{r}
# (e)
# We could add even more higher order polynomil terms or transform the variables e.g. taking the log, to try and improve the model even more. However, this will make the model more complex and we may be at risk of overfitting the data. If we overfit the data, the model wil fail to generalize well when making predictions on unseen data.

```

```{r}
# (f)
new_age_observation <- 26
# Predict using simple model
baby.predict_lm <- predict(
  baby.lm,
  data.frame(age = new_age_observation),
  interval = "prediction"
)
# Predict using quadratic model
baby.predict_lm2 <- predict(
  baby.lm2,
  data.frame(age = new_age_observation, age_square = new_age_observation^2),
  interval = "prediction"
)
# Predict using cubic model
baby.predict_lm3 <- predict(
  baby.lm3,
  data.frame(
    age = new_age_observation,
    age_square = new_age_observation^2,
    age_cubic = new_age_observation^3
  ),
  interval = "prediction"
)
"Simple model"
baby.predict_lm
"Quadratic Model"
baby.predict_lm2
"Cubic Model"
baby.predict_lm3

# The 95 % prediction interval tells us where we can expect to see a new observation with the age variable set to 26. The prediction interval will always be wider than the confidence interval as the prediction interval takes into account the true error term. We can see that prediction interval for the cubic model is much wider than the other two, i.e. the cubic model has a high variance which may be due to overfitting.
```